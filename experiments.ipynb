{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\vscode\\MLops\\Optuna\\Optuna-Hyperparameter_Tunning\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insuline</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insuline   BMI  \\\n",
       "0            6      148             72             35         0  33.6   \n",
       "1            1       85             66             29         0  26.6   \n",
       "2            8      183             64              0         0  23.3   \n",
       "3            1       89             66             23        94  28.1   \n",
       "4            0      137             40             35       168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "columns = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insuline\", \"BMI\",\n",
    "          \"DiabetesPedigreeFunction\", \"Age\", \"Outcome\" ]\n",
    "\n",
    "df = pd.read_csv(url, names = columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregnancies                 0\n",
      "Glucose                     0\n",
      "BloodPressure               0\n",
      "SkinThickness               0\n",
      "Insuline                    0\n",
      "BMI                         0\n",
      "DiabetesPedigreeFunction    0\n",
      "Age                         0\n",
      "Outcome                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#handling missing values\n",
    "cols_with_missing_values = [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insuline\", \"BMI\"]\n",
    "df[cols_with_missing_values] = df[cols_with_missing_values].replace(0, np.nan)\n",
    "\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape: (614, 8)\n",
      "test data shape: (154, 8)\n"
     ]
    }
   ],
   "source": [
    "#split into feature and target\n",
    "X = df.drop(\"Outcome\", axis = 1)\n",
    "y = df[\"Outcome\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#scaling \n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "print(f\"training data shape: {X_train.shape}\")\n",
    "print(f\"test data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#objective function\n",
    "def objective(trial):\n",
    "    #values for hyperparameters\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 200)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3,20)\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    score = cross_val_score(model, X_train, y_train, cv = 3, scoring = \"accuracy\").mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-25 23:03:35,822] A new study created in memory with name: no-name-61a5481e-6c9c-4b93-94b2-2aee96bdbab2\n",
      "[I 2025-02-25 23:03:36,497] Trial 0 finished with value: 0.7768691216323927 and parameters: {'n_estimators': 56, 'max_depth': 12}. Best is trial 0 with value: 0.7768691216323927.\n",
      "[I 2025-02-25 23:03:38,363] Trial 1 finished with value: 0.7833652160051012 and parameters: {'n_estimators': 164, 'max_depth': 13}. Best is trial 1 with value: 0.7833652160051012.\n",
      "[I 2025-02-25 23:03:40,355] Trial 2 finished with value: 0.7670731707317073 and parameters: {'n_estimators': 161, 'max_depth': 19}. Best is trial 1 with value: 0.7833652160051012.\n",
      "[I 2025-02-25 23:03:43,507] Trial 3 finished with value: 0.7736011477761836 and parameters: {'n_estimators': 171, 'max_depth': 8}. Best is trial 1 with value: 0.7833652160051012.\n",
      "[I 2025-02-25 23:03:44,441] Trial 4 finished with value: 0.7735852064402997 and parameters: {'n_estimators': 52, 'max_depth': 5}. Best is trial 1 with value: 0.7833652160051012.\n",
      "[I 2025-02-25 23:03:45,385] Trial 5 finished with value: 0.7670811413996493 and parameters: {'n_estimators': 96, 'max_depth': 5}. Best is trial 1 with value: 0.7833652160051012.\n",
      "[I 2025-02-25 23:03:45,905] Trial 6 finished with value: 0.7736091184441256 and parameters: {'n_estimators': 65, 'max_depth': 6}. Best is trial 1 with value: 0.7833652160051012.\n",
      "[I 2025-02-25 23:03:47,022] Trial 7 finished with value: 0.771967160848079 and parameters: {'n_estimators': 132, 'max_depth': 9}. Best is trial 1 with value: 0.7833652160051012.\n",
      "[I 2025-02-25 23:03:47,850] Trial 8 finished with value: 0.7768691216323927 and parameters: {'n_estimators': 94, 'max_depth': 16}. Best is trial 1 with value: 0.7833652160051012.\n",
      "[I 2025-02-25 23:03:49,185] Trial 9 finished with value: 0.7800972421488921 and parameters: {'n_estimators': 159, 'max_depth': 14}. Best is trial 1 with value: 0.7833652160051012.\n",
      "[I 2025-02-25 23:03:51,334] Trial 10 finished with value: 0.7687071576598119 and parameters: {'n_estimators': 197, 'max_depth': 19}. Best is trial 1 with value: 0.7833652160051012.\n",
      "[I 2025-02-25 23:03:53,398] Trial 11 finished with value: 0.7833731866730432 and parameters: {'n_estimators': 148, 'max_depth': 13}. Best is trial 11 with value: 0.7833731866730432.\n",
      "[I 2025-02-25 23:03:55,095] Trial 12 finished with value: 0.7752510760401722 and parameters: {'n_estimators': 134, 'max_depth': 12}. Best is trial 11 with value: 0.7833731866730432.\n",
      "[I 2025-02-25 23:03:57,591] Trial 13 finished with value: 0.7752191933684043 and parameters: {'n_estimators': 191, 'max_depth': 16}. Best is trial 11 with value: 0.7833731866730432.\n",
      "[I 2025-02-25 23:03:58,871] Trial 14 finished with value: 0.7687071576598119 and parameters: {'n_estimators': 149, 'max_depth': 9}. Best is trial 11 with value: 0.7833731866730432.\n",
      "[I 2025-02-25 23:04:00,107] Trial 15 finished with value: 0.7784951378925554 and parameters: {'n_estimators': 110, 'max_depth': 15}. Best is trial 11 with value: 0.7833731866730432.\n",
      "[I 2025-02-25 23:04:02,451] Trial 16 finished with value: 0.7784871672246134 and parameters: {'n_estimators': 178, 'max_depth': 13}. Best is trial 11 with value: 0.7833731866730432.\n",
      "[I 2025-02-25 23:04:04,519] Trial 17 finished with value: 0.7784712258887295 and parameters: {'n_estimators': 147, 'max_depth': 10}. Best is trial 11 with value: 0.7833731866730432.\n",
      "[I 2025-02-25 23:04:06,133] Trial 18 finished with value: 0.7785031085604973 and parameters: {'n_estimators': 113, 'max_depth': 17}. Best is trial 11 with value: 0.7833731866730432.\n",
      "[I 2025-02-25 23:04:07,649] Trial 19 finished with value: 0.7540650406504065 and parameters: {'n_estimators': 177, 'max_depth': 3}. Best is trial 11 with value: 0.7833731866730432.\n",
      "[I 2025-02-25 23:04:09,701] Trial 20 finished with value: 0.7850071736011478 and parameters: {'n_estimators': 146, 'max_depth': 11}. Best is trial 20 with value: 0.7850071736011478.\n",
      "[I 2025-02-25 23:04:11,092] Trial 21 finished with value: 0.7833811573409851 and parameters: {'n_estimators': 145, 'max_depth': 11}. Best is trial 20 with value: 0.7850071736011478.\n",
      "[I 2025-02-25 23:04:13,328] Trial 22 finished with value: 0.7833811573409851 and parameters: {'n_estimators': 144, 'max_depth': 11}. Best is trial 20 with value: 0.7850071736011478.\n",
      "[I 2025-02-25 23:04:14,472] Trial 23 finished with value: 0.7735931771082417 and parameters: {'n_estimators': 124, 'max_depth': 10}. Best is trial 20 with value: 0.7850071736011478.\n",
      "[I 2025-02-25 23:04:16,091] Trial 24 finished with value: 0.771983102183963 and parameters: {'n_estimators': 134, 'max_depth': 11}. Best is trial 20 with value: 0.7850071736011478.\n",
      "[I 2025-02-25 23:04:17,342] Trial 25 finished with value: 0.7622110632871034 and parameters: {'n_estimators': 118, 'max_depth': 7}. Best is trial 20 with value: 0.7850071736011478.\n",
      "[I 2025-02-25 23:04:18,606] Trial 26 finished with value: 0.7833811573409851 and parameters: {'n_estimators': 142, 'max_depth': 11}. Best is trial 20 with value: 0.7850071736011478.\n",
      "[I 2025-02-25 23:04:19,467] Trial 27 finished with value: 0.7670891120675912 and parameters: {'n_estimators': 101, 'max_depth': 8}. Best is trial 20 with value: 0.7850071736011478.\n",
      "[I 2025-02-25 23:04:20,150] Trial 28 finished with value: 0.7687310696636378 and parameters: {'n_estimators': 81, 'max_depth': 11}. Best is trial 20 with value: 0.7850071736011478.\n",
      "[I 2025-02-25 23:04:22,235] Trial 29 finished with value: 0.7817312290769967 and parameters: {'n_estimators': 153, 'max_depth': 14}. Best is trial 20 with value: 0.7850071736011478.\n",
      "[I 2025-02-25 23:04:24,729] Trial 30 finished with value: 0.7768452096285668 and parameters: {'n_estimators': 184, 'max_depth': 10}. Best is trial 20 with value: 0.7850071736011478.\n",
      "[I 2025-02-25 23:04:26,344] Trial 31 finished with value: 0.78012912482066 and parameters: {'n_estimators': 140, 'max_depth': 12}. Best is trial 20 with value: 0.7850071736011478.\n",
      "[I 2025-02-25 23:04:28,304] Trial 32 finished with value: 0.7785031085604973 and parameters: {'n_estimators': 141, 'max_depth': 12}. Best is trial 20 with value: 0.7850071736011478.\n",
      "[I 2025-02-25 23:04:29,924] Trial 33 finished with value: 0.771967160848079 and parameters: {'n_estimators': 128, 'max_depth': 9}. Best is trial 20 with value: 0.7850071736011478.\n",
      "[I 2025-02-25 23:04:32,524] Trial 34 finished with value: 0.780113183484776 and parameters: {'n_estimators': 160, 'max_depth': 11}. Best is trial 20 with value: 0.7850071736011478.\n",
      "[I 2025-02-25 23:04:34,984] Trial 35 finished with value: 0.7833652160051012 and parameters: {'n_estimators': 164, 'max_depth': 13}. Best is trial 20 with value: 0.7850071736011478.\n",
      "[I 2025-02-25 23:04:36,255] Trial 36 finished with value: 0.771975131516021 and parameters: {'n_estimators': 122, 'max_depth': 8}. Best is trial 20 with value: 0.7850071736011478.\n",
      "[I 2025-02-25 23:04:38,483] Trial 37 finished with value: 0.7735931771082417 and parameters: {'n_estimators': 168, 'max_depth': 10}. Best is trial 20 with value: 0.7850071736011478.\n",
      "[I 2025-02-25 23:04:39,849] Trial 38 finished with value: 0.7768611509644509 and parameters: {'n_estimators': 141, 'max_depth': 14}. Best is trial 20 with value: 0.7850071736011478.\n",
      "[I 2025-02-25 23:04:41,064] Trial 39 finished with value: 0.7719591901801371 and parameters: {'n_estimators': 156, 'max_depth': 6}. Best is trial 20 with value: 0.7850071736011478.\n",
      "[I 2025-02-25 23:04:42,595] Trial 40 finished with value: 0.7687071576598119 and parameters: {'n_estimators': 170, 'max_depth': 7}. Best is trial 20 with value: 0.7850071736011478.\n",
      "[I 2025-02-25 23:04:44,529] Trial 41 finished with value: 0.7850071736011478 and parameters: {'n_estimators': 145, 'max_depth': 13}. Best is trial 20 with value: 0.7850071736011478.\n",
      "[I 2025-02-25 23:04:46,300] Trial 42 finished with value: 0.780121154152718 and parameters: {'n_estimators': 140, 'max_depth': 11}. Best is trial 20 with value: 0.7850071736011478.\n",
      "[I 2025-02-25 23:04:47,734] Trial 43 finished with value: 0.780113183484776 and parameters: {'n_estimators': 152, 'max_depth': 13}. Best is trial 20 with value: 0.7850071736011478.\n",
      "[I 2025-02-25 23:04:49,588] Trial 44 finished with value: 0.7752431053722302 and parameters: {'n_estimators': 130, 'max_depth': 12}. Best is trial 20 with value: 0.7850071736011478.\n",
      "[I 2025-02-25 23:04:51,034] Trial 45 finished with value: 0.7784871672246134 and parameters: {'n_estimators': 146, 'max_depth': 15}. Best is trial 20 with value: 0.7850071736011478.\n",
      "[I 2025-02-25 23:04:52,699] Trial 46 finished with value: 0.7687071576598119 and parameters: {'n_estimators': 136, 'max_depth': 9}. Best is trial 20 with value: 0.7850071736011478.\n",
      "[I 2025-02-25 23:04:54,798] Trial 47 finished with value: 0.7703331739199745 and parameters: {'n_estimators': 159, 'max_depth': 20}. Best is trial 20 with value: 0.7850071736011478.\n",
      "[I 2025-02-25 23:04:56,200] Trial 48 finished with value: 0.7850231149370317 and parameters: {'n_estimators': 118, 'max_depth': 14}. Best is trial 48 with value: 0.7850231149370317.\n",
      "[I 2025-02-25 23:04:57,466] Trial 49 finished with value: 0.7768770923003347 and parameters: {'n_estimators': 108, 'max_depth': 17}. Best is trial 48 with value: 0.7850231149370317.\n"
     ]
    }
   ],
   "source": [
    "#create a study object and optimize the objective function\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial accuracy: 0.7850231149370317\n",
      "best trial hyperparameters: {'n_estimators': 118, 'max_depth': 14}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best trial accuracy: {study.best_trial.value}\")\n",
    "print(f\"best trial hyperparameters: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuray with best hyperparameters: 0.76\n"
     ]
    }
   ],
   "source": [
    "#using the best hyperparameter values from optuna\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "best_model = RandomForestClassifier(**study.best_trial.params, random_state=42)\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test accuray with best hyperparameters: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samplers in optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 200)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 20)\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=  n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        random_state=42\n",
    "    )\n",
    "    scor = cross_val_score(model, X_train, y_train, cv = 3, scoring=\"accuracy\").mean()\n",
    "    return scor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-25 23:25:16,962] A new study created in memory with name: no-name-210c408b-ad5a-4b68-89a4-e558adf27e8a\n",
      "[I 2025-02-25 23:25:18,221] Trial 0 finished with value: 0.7638291088793241 and parameters: {'n_estimators': 85, 'max_depth': 5}. Best is trial 0 with value: 0.7638291088793241.\n",
      "[I 2025-02-25 23:25:19,746] Trial 1 finished with value: 0.7752351347042882 and parameters: {'n_estimators': 94, 'max_depth': 6}. Best is trial 1 with value: 0.7752351347042882.\n",
      "[I 2025-02-25 23:25:20,769] Trial 2 finished with value: 0.7703491152558585 and parameters: {'n_estimators': 69, 'max_depth': 20}. Best is trial 1 with value: 0.7752351347042882.\n",
      "[I 2025-02-25 23:25:21,645] Trial 3 finished with value: 0.7638370795472661 and parameters: {'n_estimators': 69, 'max_depth': 5}. Best is trial 1 with value: 0.7752351347042882.\n",
      "[I 2025-02-25 23:25:23,929] Trial 4 finished with value: 0.7605770763589988 and parameters: {'n_estimators': 179, 'max_depth': 4}. Best is trial 1 with value: 0.7752351347042882.\n",
      "[I 2025-02-25 23:25:27,064] Trial 5 finished with value: 0.776837238960625 and parameters: {'n_estimators': 199, 'max_depth': 11}. Best is trial 5 with value: 0.776837238960625.\n",
      "[I 2025-02-25 23:25:28,253] Trial 6 finished with value: 0.7589430894308943 and parameters: {'n_estimators': 129, 'max_depth': 4}. Best is trial 5 with value: 0.776837238960625.\n",
      "[I 2025-02-25 23:25:30,171] Trial 7 finished with value: 0.7817471704128806 and parameters: {'n_estimators': 165, 'max_depth': 12}. Best is trial 7 with value: 0.7817471704128806.\n",
      "[I 2025-02-25 23:25:31,039] Trial 8 finished with value: 0.7638291088793241 and parameters: {'n_estimators': 86, 'max_depth': 9}. Best is trial 7 with value: 0.7817471704128806.\n",
      "[I 2025-02-25 23:25:31,640] Trial 9 finished with value: 0.75242308305436 and parameters: {'n_estimators': 60, 'max_depth': 8}. Best is trial 7 with value: 0.7817471704128806.\n",
      "[I 2025-02-25 23:25:32,845] Trial 10 finished with value: 0.7784951378925554 and parameters: {'n_estimators': 104, 'max_depth': 18}. Best is trial 7 with value: 0.7817471704128806.\n",
      "[I 2025-02-25 23:25:35,933] Trial 11 finished with value: 0.7768611509644509 and parameters: {'n_estimators': 189, 'max_depth': 8}. Best is trial 7 with value: 0.7817471704128806.\n",
      "[I 2025-02-25 23:25:38,798] Trial 12 finished with value: 0.771983102183963 and parameters: {'n_estimators': 191, 'max_depth': 8}. Best is trial 7 with value: 0.7817471704128806.\n",
      "[I 2025-02-25 23:25:40,678] Trial 13 finished with value: 0.752415112386418 and parameters: {'n_estimators': 155, 'max_depth': 3}. Best is trial 7 with value: 0.7817471704128806.\n",
      "[I 2025-02-25 23:25:41,263] Trial 14 finished with value: 0.7540570699824646 and parameters: {'n_estimators': 61, 'max_depth': 3}. Best is trial 7 with value: 0.7817471704128806.\n",
      "[I 2025-02-25 23:25:42,498] Trial 15 finished with value: 0.771975131516021 and parameters: {'n_estimators': 95, 'max_depth': 6}. Best is trial 7 with value: 0.7817471704128806.\n",
      "[I 2025-02-25 23:25:43,916] Trial 16 finished with value: 0.7654630958074287 and parameters: {'n_estimators': 59, 'max_depth': 7}. Best is trial 7 with value: 0.7817471704128806.\n",
      "[I 2025-02-25 23:25:45,025] Trial 17 finished with value: 0.7507970667941973 and parameters: {'n_estimators': 85, 'max_depth': 3}. Best is trial 7 with value: 0.7817471704128806.\n",
      "[I 2025-02-25 23:25:46,257] Trial 18 finished with value: 0.7670731707317073 and parameters: {'n_estimators': 95, 'max_depth': 5}. Best is trial 7 with value: 0.7817471704128806.\n",
      "[I 2025-02-25 23:25:48,871] Trial 19 finished with value: 0.7735931771082417 and parameters: {'n_estimators': 168, 'max_depth': 10}. Best is trial 7 with value: 0.7817471704128806.\n",
      "[I 2025-02-25 23:25:50,791] Trial 20 finished with value: 0.7784951378925554 and parameters: {'n_estimators': 136, 'max_depth': 17}. Best is trial 7 with value: 0.7817471704128806.\n",
      "[I 2025-02-25 23:25:53,851] Trial 21 finished with value: 0.7703411445879165 and parameters: {'n_estimators': 196, 'max_depth': 18}. Best is trial 7 with value: 0.7817471704128806.\n",
      "[I 2025-02-25 23:25:55,051] Trial 22 finished with value: 0.7703570859238004 and parameters: {'n_estimators': 83, 'max_depth': 18}. Best is trial 7 with value: 0.7817471704128806.\n",
      "[I 2025-02-25 23:25:56,825] Trial 23 finished with value: 0.7752191933684043 and parameters: {'n_estimators': 176, 'max_depth': 5}. Best is trial 7 with value: 0.7817471704128806.\n",
      "[I 2025-02-25 23:25:59,475] Trial 24 finished with value: 0.7524310537223019 and parameters: {'n_estimators': 198, 'max_depth': 3}. Best is trial 7 with value: 0.7817471704128806.\n",
      "[I 2025-02-25 23:26:00,781] Trial 25 finished with value: 0.7850151442690897 and parameters: {'n_estimators': 105, 'max_depth': 16}. Best is trial 25 with value: 0.7850151442690897.\n",
      "[I 2025-02-25 23:26:03,022] Trial 26 finished with value: 0.7752271640363463 and parameters: {'n_estimators': 170, 'max_depth': 9}. Best is trial 25 with value: 0.7850151442690897.\n",
      "[I 2025-02-25 23:26:05,571] Trial 27 finished with value: 0.7866331898613104 and parameters: {'n_estimators': 163, 'max_depth': 13}. Best is trial 27 with value: 0.7866331898613104.\n",
      "[I 2025-02-25 23:26:08,364] Trial 28 finished with value: 0.7703411445879165 and parameters: {'n_estimators': 190, 'max_depth': 20}. Best is trial 27 with value: 0.7866331898613104.\n",
      "[I 2025-02-25 23:26:11,288] Trial 29 finished with value: 0.7686991869918699 and parameters: {'n_estimators': 165, 'max_depth': 19}. Best is trial 27 with value: 0.7866331898613104.\n",
      "[I 2025-02-25 23:26:12,616] Trial 30 finished with value: 0.771975131516021 and parameters: {'n_estimators': 89, 'max_depth': 12}. Best is trial 27 with value: 0.7866331898613104.\n",
      "[I 2025-02-25 23:26:13,867] Trial 31 finished with value: 0.7703570859238004 and parameters: {'n_estimators': 86, 'max_depth': 15}. Best is trial 27 with value: 0.7866331898613104.\n",
      "[I 2025-02-25 23:26:16,261] Trial 32 finished with value: 0.7833811573409851 and parameters: {'n_estimators': 143, 'max_depth': 14}. Best is trial 27 with value: 0.7866331898613104.\n",
      "[I 2025-02-25 23:26:18,509] Trial 33 finished with value: 0.7752112227004623 and parameters: {'n_estimators': 158, 'max_depth': 10}. Best is trial 27 with value: 0.7866331898613104.\n",
      "[I 2025-02-25 23:26:20,853] Trial 34 finished with value: 0.7768531802965088 and parameters: {'n_estimators': 146, 'max_depth': 20}. Best is trial 27 with value: 0.7866331898613104.\n",
      "[I 2025-02-25 23:26:21,826] Trial 35 finished with value: 0.76385302088315 and parameters: {'n_estimators': 65, 'max_depth': 9}. Best is trial 27 with value: 0.7866331898613104.\n",
      "[I 2025-02-25 23:26:22,951] Trial 36 finished with value: 0.7768611509644509 and parameters: {'n_estimators': 103, 'max_depth': 20}. Best is trial 27 with value: 0.7866331898613104.\n",
      "[I 2025-02-25 23:26:24,158] Trial 37 finished with value: 0.771983102183963 and parameters: {'n_estimators': 85, 'max_depth': 17}. Best is trial 27 with value: 0.7866331898613104.\n",
      "[I 2025-02-25 23:26:27,172] Trial 38 finished with value: 0.7735931771082417 and parameters: {'n_estimators': 200, 'max_depth': 18}. Best is trial 27 with value: 0.7866331898613104.\n",
      "[I 2025-02-25 23:26:28,558] Trial 39 finished with value: 0.7768531802965088 and parameters: {'n_estimators': 133, 'max_depth': 10}. Best is trial 27 with value: 0.7866331898613104.\n",
      "[I 2025-02-25 23:26:30,882] Trial 40 finished with value: 0.7784791965566714 and parameters: {'n_estimators': 199, 'max_depth': 9}. Best is trial 27 with value: 0.7866331898613104.\n",
      "[I 2025-02-25 23:26:33,257] Trial 41 finished with value: 0.7752112227004623 and parameters: {'n_estimators': 179, 'max_depth': 16}. Best is trial 27 with value: 0.7866331898613104.\n",
      "[I 2025-02-25 23:26:34,174] Trial 42 finished with value: 0.771983102183963 and parameters: {'n_estimators': 96, 'max_depth': 6}. Best is trial 27 with value: 0.7866331898613104.\n",
      "[I 2025-02-25 23:26:35,389] Trial 43 finished with value: 0.7752351347042882 and parameters: {'n_estimators': 123, 'max_depth': 15}. Best is trial 27 with value: 0.7866331898613104.\n",
      "[I 2025-02-25 23:26:36,039] Trial 44 finished with value: 0.7784951378925554 and parameters: {'n_estimators': 65, 'max_depth': 16}. Best is trial 27 with value: 0.7866331898613104.\n",
      "[I 2025-02-25 23:26:37,321] Trial 45 finished with value: 0.7768531802965088 and parameters: {'n_estimators': 133, 'max_depth': 10}. Best is trial 27 with value: 0.7866331898613104.\n",
      "[I 2025-02-25 23:26:39,252] Trial 46 finished with value: 0.7736011477761836 and parameters: {'n_estimators': 177, 'max_depth': 8}. Best is trial 27 with value: 0.7866331898613104.\n",
      "[I 2025-02-25 23:26:40,018] Trial 47 finished with value: 0.7703491152558585 and parameters: {'n_estimators': 78, 'max_depth': 16}. Best is trial 27 with value: 0.7866331898613104.\n",
      "[I 2025-02-25 23:26:40,901] Trial 48 finished with value: 0.7687071576598119 and parameters: {'n_estimators': 88, 'max_depth': 8}. Best is trial 27 with value: 0.7866331898613104.\n",
      "[I 2025-02-25 23:26:41,631] Trial 49 finished with value: 0.771983102183963 and parameters: {'n_estimators': 72, 'max_depth': 18}. Best is trial 27 with value: 0.7866331898613104.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.RandomSampler())\n",
    "study.optimize(objective, n_trials = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best trial accuracy: 0.7866331898613104\n",
      "best trial hyperparameter: {'n_estimators': 163, 'max_depth': 13}\n"
     ]
    }
   ],
   "source": [
    "print(f\"best trial accuracy: {study.best_trial.value}\")\n",
    "print(f\"best trial hyperparameter: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of with best hyperparameter: 0.7467532467532467\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "best_model = RandomForestClassifier(**study.best_trial.params)\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"accuracy of with best hyperparameter: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-25 23:33:44,699] A new study created in memory with name: no-name-de255f5e-194c-443f-a40f-0f75a8124ba3\n",
      "[I 2025-02-25 23:33:45,775] Trial 0 finished with value: 0.7654391838036028 and parameters: {'n_estimators': 100, 'max_depth': 5}. Best is trial 0 with value: 0.7654391838036028.\n",
      "[I 2025-02-25 23:33:47,598] Trial 1 finished with value: 0.7735772357723577 and parameters: {'n_estimators': 150, 'max_depth': 10}. Best is trial 1 with value: 0.7735772357723577.\n",
      "[I 2025-02-25 23:33:48,142] Trial 2 finished with value: 0.7687151283277539 and parameters: {'n_estimators': 50, 'max_depth': 15}. Best is trial 1 with value: 0.7735772357723577.\n",
      "[I 2025-02-25 23:33:49,293] Trial 3 finished with value: 0.7752351347042882 and parameters: {'n_estimators': 100, 'max_depth': 15}. Best is trial 3 with value: 0.7752351347042882.\n",
      "[I 2025-02-25 23:33:50,464] Trial 4 finished with value: 0.7703491152558585 and parameters: {'n_estimators': 100, 'max_depth': 20}. Best is trial 3 with value: 0.7752351347042882.\n",
      "[I 2025-02-25 23:33:51,096] Trial 5 finished with value: 0.7817391997449387 and parameters: {'n_estimators': 50, 'max_depth': 10}. Best is trial 5 with value: 0.7817391997449387.\n",
      "[I 2025-02-25 23:33:53,619] Trial 6 finished with value: 0.7719591901801371 and parameters: {'n_estimators': 150, 'max_depth': 5}. Best is trial 5 with value: 0.7817391997449387.\n",
      "[I 2025-02-25 23:33:55,471] Trial 7 finished with value: 0.7719591901801371 and parameters: {'n_estimators': 150, 'max_depth': 20}. Best is trial 5 with value: 0.7817391997449387.\n",
      "[I 2025-02-25 23:33:57,419] Trial 8 finished with value: 0.7784791965566714 and parameters: {'n_estimators': 150, 'max_depth': 15}. Best is trial 5 with value: 0.7817391997449387.\n",
      "[I 2025-02-25 23:34:00,032] Trial 9 finished with value: 0.7784712258887295 and parameters: {'n_estimators': 200, 'max_depth': 10}. Best is trial 5 with value: 0.7817391997449387.\n",
      "[I 2025-02-25 23:34:02,688] Trial 10 finished with value: 0.7719591901801371 and parameters: {'n_estimators': 200, 'max_depth': 20}. Best is trial 5 with value: 0.7817391997449387.\n",
      "[I 2025-02-25 23:34:05,743] Trial 11 finished with value: 0.7768611509644509 and parameters: {'n_estimators': 200, 'max_depth': 15}. Best is trial 5 with value: 0.7817391997449387.\n",
      "[I 2025-02-25 23:34:09,192] Trial 12 finished with value: 0.7768452096285668 and parameters: {'n_estimators': 200, 'max_depth': 5}. Best is trial 5 with value: 0.7817391997449387.\n",
      "[I 2025-02-25 23:34:10,048] Trial 13 finished with value: 0.7703411445879165 and parameters: {'n_estimators': 50, 'max_depth': 5}. Best is trial 5 with value: 0.7817391997449387.\n",
      "[I 2025-02-25 23:34:11,411] Trial 14 finished with value: 0.7752351347042882 and parameters: {'n_estimators': 100, 'max_depth': 10}. Best is trial 5 with value: 0.7817391997449387.\n",
      "[I 2025-02-25 23:34:11,971] Trial 15 finished with value: 0.7752112227004623 and parameters: {'n_estimators': 50, 'max_depth': 20}. Best is trial 5 with value: 0.7817391997449387.\n"
     ]
    }
   ],
   "source": [
    "#GridSampler\n",
    "search_space = {\n",
    "    \"n_estimators\" : [50, 100, 150, 200],\n",
    "    \"max_depth\" : [5,10, 15, 20]\n",
    "}\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler = optuna.samplers.GridSampler(search_space))\n",
    "study.optimize(objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best trial accurac: 0.7817391997449387\n",
      "best trial hyperparameter: {'n_estimators': 50, 'max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "print(f\"best trial accurac: {study.best_trial.value}\")\n",
    "print(f\"best trial hyperparameter: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model acc: 0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "best_model = RandomForestClassifier(**study.best_trial.params, random_state = 42)\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"best model acc: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optuna visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_optimization_history, plot_parallel_coordinate, plot_slice, plot_contour, plot_param_importances\n",
    "import plotly\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'png'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32md:\\vscode\\MLops\\Optuna\\Optuna-Hyperparameter_Tunning\\venv\\Lib\\site-packages\\optuna\\visualization\\_plotly_imports.py:7\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m try_import() \u001b[38;5;28;01mas\u001b[39;00m _imports:\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplotly\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m plotly_version\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplot_optimization_history\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32md:\\vscode\\MLops\\Optuna\\Optuna-Hyperparameter_Tunning\\venv\\Lib\\site-packages\\optuna\\visualization\\_optimization_history.py:200\u001b[0m, in \u001b[0;36mplot_optimization_history\u001b[1;34m(study, target, target_name, error_bar)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mplot_optimization_history\u001b[39m(\n\u001b[0;32m    173\u001b[0m     study: Study \u001b[38;5;241m|\u001b[39m Sequence[Study],\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    177\u001b[0m     error_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    178\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgo.Figure\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    179\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Plot optimization history of all trials in a study.\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \n\u001b[0;32m    181\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;124;03m        A :class:`plotly.graph_objects.Figure` object.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m     \u001b[43m_imports\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m     info_list \u001b[38;5;241m=\u001b[39m _get_optimization_history_info_list(study, target, target_name, error_bar)\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _get_optimization_history_plot(info_list, target_name)\n",
      "File \u001b[1;32md:\\vscode\\MLops\\Optuna\\Optuna-Hyperparameter_Tunning\\venv\\Lib\\site-packages\\optuna\\_imports.py:94\u001b[0m, in \u001b[0;36m_DeferredImportExceptionContextManager.check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deferred \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     exc_value, message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deferred\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc_value\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'."
     ]
    }
   ],
   "source": [
    "plot_optimization_history(study).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parallel_coordinate(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_contour(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_param_importances(study).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimizing multiple ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    classifier_name = trial.suggest_categorical(\"classifier\", [\"SVM\", \"RandomForest\", \"GrdientBoosting\"])\n",
    "\n",
    "    if classifier_name  == \"SVM\":\n",
    "        c = trial.suggest_float(\"C\", 0.1, 100, log = True)\n",
    "        kernel = trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\", \"poly\", \"sigmoid\"])\n",
    "        gamma = trial.suggest_categorical(\"gamma\", [\"scale\", \"auto\"])\n",
    "\n",
    "        model = SVC(C = c, kernel=kernel, gamma=gamma, random_state=42)\n",
    "\n",
    "    elif classifier_name == \"RandomForest\":\n",
    "        n_estimators = trial.suggest_int(\"n_estimators\", 50, 300)\n",
    "        max_depth = trial.suggest_int(\"max_depth\", 3, 20)\n",
    "        min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10)\n",
    "        min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n",
    "        bootstrap = trial.suggest_categorical(\"bootstrap\", [True, False])\n",
    "\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            bootstrap=bootstrap,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    elif classifier_name == \"GradientBoosting\":\n",
    "        n_estimators = trial.suggest_int(\"n_estimators\", 50, 300)\n",
    "        learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.3, log = True)\n",
    "        max_depth = trial.suggest_int(\"max_depth\", 3, 20)\n",
    "        min_samples_split = trial.suggest_int('min_sample_split', 2,10)\n",
    "        min_samples_leaf = trial.suggest_int(\"min_sample_leaf\", 1,10)\n",
    "\n",
    "        model = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            learning_rate=learning_rate,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state = 42\n",
    "        )\n",
    "\n",
    "    score = cross_val_score(model, X_train, y_train, scoring=\"accuracy\").mean()\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study=optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trails = 150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = study.best_trial\n",
    "print(\"best trial accuracy: \", best_trial.value)\n",
    "print(\"best_trial_params: \", best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.trials_dataframe()[\"params_classifier\"].vlaue_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.trials_dataframe().groupbu(\"params_classifier\")[\"value\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimization_history(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_param_importances(study).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## experiment on iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"verbosity\":0,\n",
    "        \"objective\":\"multi:softprob\",\n",
    "        \"num_class\":3,\n",
    "        \"eval_metric\":\"mlogloss\",\n",
    "        \"booster\":\"gbtree\",\n",
    "        \"lambda\":trial.suggest_float(\"lambda\", 1e-8, 1.0, log = True),\n",
    "        \"alpha\":trial.suggest_float(\"alpha\", 1e-8, 1.0, log = True),\n",
    "        \"ete\":trial.suggest_float(\"eta\", 0.01, 0.3),\n",
    "        \"gamma\":trial.suggest_float(\"gamma\", 1e-8, 1.0, log= True),\n",
    "        \"max_depth\":trial.suggest_int(\"max_depth\", 3, 9),\n",
    "        \"min_child_weight\":trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"subsample\":trial.suggest_float(\"subsample\", 0.4, 1.0),\n",
    "        \"colsample_bytree\":trial.suggest_float(\"colsample_bytree\", trial.suggest_float(\"colsample_bytree\", 0.4, 1.0)),\n",
    "        \"n_estimators\":300,\n",
    "    }\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, label = y_train)\n",
    "    dtest = xgb.DMatrix(X_test, label = y_test)\n",
    "\n",
    "    pruning_callback = optuna.integration.XGBoostPruningCallback(trial, \"eval_mlogloss\")\n",
    "\n",
    "    bst = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round = 300,\n",
    "        evals = [(dtrain, \"train\"), (dtest, \"eval\")],\n",
    "        early_stopping_rounds = 30,\n",
    "        callbacks = [pruning_callback]\n",
    "    )\n",
    "\n",
    "    #prediction\n",
    "    preds = bst.predict(dtest)\n",
    "    best_preds = [int(np.argmax(line)) for line in preds]\n",
    "\n",
    "    #return acc as objective value\n",
    "    accuracy = accuracy_score(y_test, best_preds)\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.SuccessiveHalvingPruner())\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(f\"best trial: {study.best_params}\")\n",
    "print(f\"best acc: {study.best_value}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_intermediate_values\n",
    "plot_intermediate_values(study).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
